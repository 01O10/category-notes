[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "category",
    "section": "",
    "text": "Preface\nThere are notes on Category Theory."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "",
    "text": "2 The Low-Level Perspective\nAt the lowest level of computing, everything is just bytes—binary sequences of 0s and 1s. These bytes represent data—whether numbers, text, images, or sound—everything you interact with on your computer is ultimately made up of bytes.\nFor example, consider the byte 01001000. In binary encoding, this byte represents the character 'H' in the ASCII character set. Similarly, 01100101 represents 'e', and 01101100 represents 'l'. A sequence of these bytes might represent an entire message, such as the word “Hello”.\nBytes are the raw material of computing, but they don’t mean much on their own unless we impose some structure. That’s where types come in. Type theory provides a way to give structure to these raw bytes. In a type system, we classify data into categories or types. This makes it easier to reason about and manipulate the data. For instance, we could classify 01001000 as a character or 01100101 as an integer, depending on the context.\nAlthough type theory was originally developed to improve computing, its roots lie in mathematics. The history of type theory can be traced back to logical paradoxes in set theory. Let’s explore one of the most famous of these paradoxes: Russell’s Paradox.\nRussell’s type system was the precursor to type theory as we know it today. He proposed a hierarchy of sets—called types—to organize sets and avoid paradoxes like the one above.\nMathematicians often debate whether mathematics is an invention of the human mind or a discovery of universal truths. Unlike physicists, who conduct experiments to uncover the natural laws of the universe, mathematicians engage in abstract reasoning and logical deduction. Despite this, different branches of mathematics often uncover equivalent structures, suggesting that there may be some underlying objective reality to these concepts.\nHumans evolved primarily for survival—identifying threats, securing food, and navigating social relationships. Our brains are excellent at dealing with concrete, immediate problems, but abstract reasoning is a more recent development. To handle complexity, we often use decomposition—breaking complex problems into simpler, manageable parts.\nThis principle, found in everything from science to programming, is central to how we understand and solve problems.\nIn physics, scientists have long adhered to a reductionist approach—breaking matter down into smaller and smaller components. For instance, atoms are composed of protons, neutrons, and electrons, which are themselves composed of quarks. However, recent developments in physics challenge this reductionist view:\nThese discoveries raise a profound question: is the universe inherently composable, or is this just a human cognitive strategy?\nCategory theory, often seen as a highly abstract branch of mathematics, may not be as concerned with the intrinsic nature of the universe as we might think. Instead, it provides a framework for understanding how humans reason about complexity. It describes patterns and structures that our minds impose on the problems we encounter.\nIn this sense, category theory might be more about epistemology—how we understand the world—than ontology—what the world actually is."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "intro.html#russells-paradox-a-deeper-look",
    "href": "intro.html#russells-paradox-a-deeper-look",
    "title": "1  Introduction: Understanding Category Theory, Type Theory, and Logic.",
    "section": "3.1 Russell’s Paradox: A Deeper Look",
    "text": "3.1 Russell’s Paradox: A Deeper Look\nRussell’s Paradox is a fundamental issue in set theory, discovered by Bertrand Russell in 1901. It reveals a contradiction when we consider sets that contain themselves. Here’s how the paradox works:\n\nLet’s define a set ( R ) as the set of all sets that do not contain themselves.\nThe paradox arises when we ask: Does the set ( R ) contain itself?\n\n\nIf ( R ) contains itself, then by definition it should not contain itself (since it only contains sets that do not contain themselves).\nIf ( R ) does not contain itself, then it must contain itself (since it is one of the sets that do not contain themselves).\n\nThis creates a logical contradiction. Russell proposed a solution to this by introducing a type system to organize sets into different levels or types, ensuring that a set cannot be a member of itself. This approach is foundational to type theory."
  },
  {
    "objectID": "intro.html#key-ideas-in-mltt",
    "href": "intro.html#key-ideas-in-mltt",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "5.1 Key Ideas in MLTT",
    "text": "5.1 Key Ideas in MLTT\n\n5.1.1 Types as Sets\nIn MLTT, types are collections of objects, similar to sets in set theory. For example, the type Nat (natural numbers) contains objects like 0, 1, 2, etc.\n\n5.1.1.1 Example:\nLet’s define the type Nat: - Nat = {0, 1, 2, 3, ...}.\nThis means the elements of the type Nat are natural numbers.\n\n\n\n5.1.2 2. Types as Propositions\nIn MLTT, types can also represent logical propositions. A type A → B represents the proposition “if A is true, then B is true.”\n\n5.1.2.1 Example:\nLet A be the type of natural numbers greater than 0, and B be the type of even numbers: - A = {1, 2, 3, 4, ...}. - B = {2, 4, 6, 8, ...}.\nThe type A → B means “if a number is greater than 0, then it is an even number.”\n\n\n\n5.1.3 3. Proofs as Objects\nIn MLTT, a proof of a proposition is itself a term of a specific type. So, a proof of A → B is a function that takes an element of type A and returns an element of type B.\n\n5.1.3.1 Example:\nLet’s define a function f: A → B that proves “if a number is greater than 0, then it is even.” We could define f as follows: - f(1) = 2, f(2) = 4, f(3) = 6, etc.\nHere, f is a function that constructs even numbers, proving the implication A → B.\n\n\n\n5.1.4 4. Constructive Proofs\nMLTT insists on constructive proofs. This means if we prove the existence of an object, we must provide a concrete example.\n\n5.1.4.1 Example:\nTo prove “there exists an even number greater than 0,” we must construct such a number: - f: Nat where f could return 2, which is the smallest even number greater than 0."
  },
  {
    "objectID": "intro.html#example-demonstration-proof-of-implication",
    "href": "intro.html#example-demonstration-proof-of-implication",
    "title": "1  Introduction: Understanding Category Theory, Type Theory, and Logic.",
    "section": "5.2 Example Demonstration (Proof of Implication):",
    "text": "5.2 Example Demonstration (Proof of Implication):\nLet’s consider proving ( A B ), where ( A ) and ( B ) are two types (propositions):\n\nTo prove ( A B ), we need to construct a function that takes an element of type ( A ) and returns an element of type ( B ).\nSuppose we have a specific function ( f ) that takes an element of type ( A ) and produces an element of type ( B ). We now have a proof of ( A B ), because we’ve explicitly constructed a way to transform an element of type ( A ) into an element of type ( B ).\n\nThis idea supports the notion that types and programs are closely connected, forming the foundation for functional programming."
  },
  {
    "objectID": "intro.html#key-components-of-the-isomorphism",
    "href": "intro.html#key-components-of-the-isomorphism",
    "title": "1  Introduction: Understanding Category Theory, Type Theory, and Logic.",
    "section": "6.1 Key Components of the Isomorphism:",
    "text": "6.1 Key Components of the Isomorphism:\n\nLogic ↔︎ Type Theory:\n\nLogic: In traditional logic, a proof is an argument that demonstrates the truth of a statement.\nType Theory: In type theory, a type is like a proposition, and a term (a piece of code or construction) is a proof of that type.\n\nThe correspondence is as follows:\n\nPropositions in logic correspond to types in type theory.\nProofs in logic correspond to terms in type theory.\n\nExample: In logic, the statement “If ( A ), then ( B )” (denoted ( A B )) is a proposition. In type theory, ( A B ) is a type, and a proof of this statement is a term (a function) that transforms an element of type ( A ) into an element of type ( B ).\nType Theory ↔︎ Category Theory:\n\nCategory Theory: Category theory deals with objects and morphisms (arrows) between objects. A category is a collection of objects and morphisms that satisfy certain conditions.\nIn category theory, a morphism can be thought of as a structure-preserving transformation between two objects. In type theory, a term is analogous to a morphism, and a type is analogous to an object.\n\nThe Curry-Howard-Lambek isomorphism shows that there is a close relationship between types, terms, propositions, and proofs, as well as between categories and types."
  },
  {
    "objectID": "intro.html#step-by-step-example-the-logic-to-type-theory-correspondence",
    "href": "intro.html#step-by-step-example-the-logic-to-type-theory-correspondence",
    "title": "1  Introduction: Understanding Category Theory, Type Theory, and Logic.",
    "section": "6.2 Step-by-Step Example (The Logic to Type Theory Correspondence):",
    "text": "6.2 Step-by-Step Example (The Logic to Type Theory Correspondence):\nLet’s consider the implication ( A B ) and how it corresponds to type theory:\n\nLogical View:\n\nThe statement ( A B ) means “if ( A ) is true, then ( B ) is true”.\nA proof of this statement is a series of logical steps that leads from ( A ) to ( B ).\n\nType Theory View:\n\n( A B ) is a type in type theory, where we expect a function that takes an input of type ( A ) and returns an output of type ( B ).\nA term of type ( A B ) is a function that can transform elements of type ( A ) into elements of type ( B ). This is akin to a proof of ( A B ) in logic.\n\n\nIn this sense, proving a logical implication is the same as writing a function in type theory. This is a key insight of the Curry-Howard-Lambek Isomorphism."
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "3  Relations and Functions",
    "section": "",
    "text": "4 Relations\nA function is:\nUnderstanding functions and relations helps in many fields, from mathematics to computer science. Knowing when a function is invertible, injective, or surjective allows us to determine how information is preserved, mapped, and structured.\nBy mastering these concepts, you can better analyze transformations, abstractions, and models in various domains."
  },
  {
    "objectID": "functions.html#what-is-a-relation",
    "href": "functions.html#what-is-a-relation",
    "title": "3  Relations and Functions",
    "section": "4.1 What is a Relation?",
    "text": "4.1 What is a Relation?\nA relation is a set of ordered pairs where elements from one set are associated with elements from another set.\nFor example, if we have two sets:\n\n\\(A = \\{1, 2, 3\\}\\)\n\\(B = \\{a, b, c\\}\\)\n\nA relation between them could be:\n\\[\nR = \\{(1, a), (2, b), (3, c)\\}\n\\]"
  },
  {
    "objectID": "functions.html#relations-and-cartesian-products",
    "href": "functions.html#relations-and-cartesian-products",
    "title": "3  Relations and Functions",
    "section": "4.2 Relations and Cartesian Products",
    "text": "4.2 Relations and Cartesian Products\nA relation can be understood through the Cartesian product of two sets. The Cartesian product \\(A \\times B\\) consists of all possible pairs:\n\\[\nA \\times B = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c), (3, a), (3, b), (3, c)\\}\n\\]\nA relation is simply a subset of this Cartesian product."
  },
  {
    "objectID": "functions.html#what-is-a-function",
    "href": "functions.html#what-is-a-function",
    "title": "3  Relations and Functions",
    "section": "5.1 What is a Function?",
    "text": "5.1 What is a Function?\nA function is a special type of relation that has a well-defined directionality: each input from the domain is mapped to exactly one output in the codomain."
  },
  {
    "objectID": "functions.html#key-properties-of-functions",
    "href": "functions.html#key-properties-of-functions",
    "title": "3  Relations and Functions",
    "section": "5.2 Key Properties of Functions",
    "text": "5.2 Key Properties of Functions\n\nA function must assign exactly one output to each input.\nThe domain is the set of all possible inputs.\nThe codomain is the set of possible outputs (though not necessarily all elements in the codomain are used).\nThe actual values a function maps to are called the image of the function.\n\nFor example, if we define a function \\(f: A \\to B\\) as:\n\\[\nf(x) = x^2, \\quad A = \\{1, 2, 3\\}, \\quad B = \\{1, 4, 9, 10\\}\n\\]\nThen:\n\\[\nf(1) = 1, \\quad f(2) = 4, \\quad f(3) = 9\n\\]"
  },
  {
    "objectID": "functions.html#total-functions-vs.-partial-functions",
    "href": "functions.html#total-functions-vs.-partial-functions",
    "title": "3  Relations and Functions",
    "section": "5.3 Total Functions vs. Partial Functions",
    "text": "5.3 Total Functions vs. Partial Functions\n\nA total function maps every element of the domain to an element in the codomain.\nA partial function may leave some elements of the domain unmapped."
  },
  {
    "objectID": "functions.html#when-is-a-function-invertible",
    "href": "functions.html#when-is-a-function-invertible",
    "title": "3  Relations and Functions",
    "section": "6.1 When is a Function Invertible?",
    "text": "6.1 When is a Function Invertible?\nA function is invertible if there exists another function that can reverse its effect. That is, given an output, we can determine the unique input that produced it.\nExample: If \\(f(x) = x + 2\\), the inverse function is \\(g(x) = x - 2\\), because applying \\(g\\) after \\(f\\) returns the original input:\n\\[\ng(f(x)) = (x + 2) - 2 = x\n\\]\nNot all functions are invertible! A function must be bijective (both injective and surjective) to have an inverse."
  },
  {
    "objectID": "functions.html#what-is-an-isomorphism",
    "href": "functions.html#what-is-an-isomorphism",
    "title": "3  Relations and Functions",
    "section": "7.1 What is an Isomorphism?",
    "text": "7.1 What is an Isomorphism?\nAn isomorphism is a function that has a perfect inverse—it maps one set to another in a way that preserves structure.\nGiven two functions:\n\n\\(f: A \\to B\\)\n\\(g: B \\to A\\)\n\n\\(f\\) and \\(g\\) are isomorphic if:\n\\[\ng \\circ f = id_A \\quad \\text{and} \\quad f \\circ g = id_B\n\\]\nwhere \\(id_A\\) and \\(id_B\\) are identity functions that return their input unchanged."
  },
  {
    "objectID": "functions.html#why-are-functions-non-isomorphic",
    "href": "functions.html#why-are-functions-non-isomorphic",
    "title": "3  Relations and Functions",
    "section": "7.2 Why are Functions Non-Isomorphic?",
    "text": "7.2 Why are Functions Non-Isomorphic?\nThere are two main reasons why a function might not be an isomorphism:\n\n7.2.1 1. Loss of Information: Non-Injective Functions\nA function is not injective if multiple inputs map to the same output (collapsing elements).\nExample: \\[\nf(x) = x^2\n\\]\nHere, both \\(f(2) = 4\\) and \\(f(-2) = 4\\), so the function is not invertible because we lose information about whether the input was positive or negative.\n\nOpposite Property: A function is injective (one-to-one) if no two inputs map to the same output.\nRelated concept: Monomorphism (monic functions).\n\n\n\n7.2.2 2. Incomplete Coverage: Non-Surjective Functions\nA function is not surjective if it does not cover the entire codomain.\nExample: Suppose \\(f: \\mathbb{R} \\to \\mathbb{R}\\) is defined by:\n\\[\nf(x) = e^x\n\\]\nSince the function never produces negative numbers, it is not surjective onto \\(\\mathbb{R}\\).\n\nOpposite Property: A function is surjective (onto) if it covers the entire codomain.\nRelated concept: Epimorphism (epic functions)."
  },
  {
    "objectID": "functions.html#why-is-a-bijective-function-an-isomorphism",
    "href": "functions.html#why-is-a-bijective-function-an-isomorphism",
    "title": "3  Relations and Functions",
    "section": "8.1 Why is a Bijective Function an Isomorphism?",
    "text": "8.1 Why is a Bijective Function an Isomorphism?\nA bijective function is an isomorphism because it:\n\nPreserves uniqueness (no collapsing).\nFully maps the codomain (no gaps).\nHas an inverse function that undoes its effect.\n\nExample:\nThe function \\(f(x) = x + 3\\) is bijective because:\n\nIt is injective (each \\(x\\) gives a unique output).\nIt is surjective (covers all real numbers).\nIt has an inverse \\(g(x) = x - 3\\), making it an isomorphism."
  },
  {
    "objectID": "category_theory.html",
    "href": "category_theory.html",
    "title": "2  Associativity and its Role in Categories",
    "section": "",
    "text": "3 Programming and Category Theory\nCategory theory offers a framework for thinking about mathematical structures and their relationships in an abstract, high-level way. By focusing on morphisms and their composition, we can study the properties of objects without needing to understand their internal details. This approach to abstraction leads to new insights into mathematics and computation, ultimately enabling a deeper understanding of how various structures are interconnected."
  },
  {
    "objectID": "category_theory.html#is-it-possible-to-have-non-associative-theories",
    "href": "category_theory.html#is-it-possible-to-have-non-associative-theories",
    "title": "2  Associativity and its Role in Categories",
    "section": "2.1 Is it Possible to Have Non-Associative Theories?",
    "text": "2.1 Is it Possible to Have Non-Associative Theories?\nIn category theory, associativity is an important property. When combining elements in a category, you can associate them in different ways, but as long as associativity holds, the result will be the same. This property makes working with categories manageable and consistent.\nBut what if we didn’t require strict associativity? Is it still possible to have a valid theory? The answer is yes. There are areas in mathematics where associativity is weakened: the two different ways of combining things aren’t identical, but they are isomorphic. This means they are related in a way that one can be transformed into the other.\n\n2.1.1 Example: Floating Point Arithmetic\nFor example, in floating point arithmetic, the order of operations may result in slightly different results due to the finite precision of calculations. This does not form a valid category since strict associativity is required for categories."
  },
  {
    "objectID": "category_theory.html#categories-vs.-groups",
    "href": "category_theory.html#categories-vs.-groups",
    "title": "2  Associativity and its Role in Categories",
    "section": "2.2 Categories vs. Groups",
    "text": "2.2 Categories vs. Groups\nThe structure described in category theory shares some similarities with groups, but it is more general. A group is a type of monoid with an added property: every element has an inverse.\nIf every morphism (arrow) in a category has an inverse, the category becomes a groupoid. A groupoid is more general than a group because a group only has one object with its operations, whereas a category can have multiple objects with morphisms between them.\nThe distinction between groups and categories is that in a category, not all objects can be composed with each other. The ability to compose objects depends on whether the end of one morphism matches the start of another."
  },
  {
    "objectID": "category_theory.html#the-category-of-types",
    "href": "category_theory.html#the-category-of-types",
    "title": "2  Associativity and its Role in Categories",
    "section": "3.1 The Category of Types",
    "text": "3.1 The Category of Types\nA practical example of category theory comes from programming languages such as Haskell and ML. In these languages, types can be treated as objects, and functions between types are the morphisms of the category.\nIn these programming categories, a function from type A to type B is considered an arrow or morphism from object A to object B.\n\n3.1.1 Special Case in Haskell\nIn Haskell, things are slightly more complicated due to the concept of laziness. In Haskell, every type contains an undefined value (bottom) which represents non-terminating computations. This introduces a level of complexity that is not typically considered in pure category theory, as categories don’t account for time or infinite loops in computation."
  },
  {
    "objectID": "category_theory.html#types-as-sets",
    "href": "category_theory.html#types-as-sets",
    "title": "2  Associativity and its Role in Categories",
    "section": "3.2 Types as Sets",
    "text": "3.2 Types as Sets\nIn some programming languages like ML, types can be viewed as sets of values. The functions between these types are simply functions between sets. This simplification works well in languages that don’t have infinite loops or non-terminating computations, unlike Haskell.\nThus, we can model a category of types as a category of sets. In this model, functions are the morphisms, and types are sets of values. A function from type A to type B becomes a mathematical function between sets A and B."
  },
  {
    "objectID": "category_theory.html#set-theory-and-categories",
    "href": "category_theory.html#set-theory-and-categories",
    "title": "2  Associativity and its Role in Categories",
    "section": "4.1 Set Theory and Categories",
    "text": "4.1 Set Theory and Categories\nTo build a category, you start with sets. In set theory, each set contains elements, and functions between sets are simply mappings from elements of one set to another. From this perspective, you can form a category where:\n\nThe objects are the sets.\nThe morphisms are the functions between the sets.\n\n\n4.1.1 Forgetting Internal Structure\nOnce the category is created, the internal structure of the sets is forgotten. All that remains are the morphisms that relate the sets to each other. The composition of these morphisms follows the rules of category theory, with associativity and identity being central properties.\n\n\n4.1.2 Composition of Functions\nFunction composition in set theory is simply the act of applying one function to the result of another. If f: A -&gt; B and g: B -&gt; C, then the composition g ∘ f is a function that takes A to C.\n\nIf x is an element of set A, f(x) is an element of set B.\nThen g(f(x)) is an element of set C.\n\n\n\n4.1.3 Identity Function\nEach set also has an identity function. This is a function that maps each element of a set to itself. The identity function acts as a neutral element in function composition: when composed with any other function, it leaves that function unchanged.\n\nIn a category, the identity function corresponds to an identity morphism.\nFor any morphism f, composing it with the identity morphism gives back the original morphism: f ∘ id_A = f and id_B ∘ f = f."
  },
  {
    "objectID": "category_theory.html#the-category-of-sets-set-theory",
    "href": "category_theory.html#the-category-of-sets-set-theory",
    "title": "2  Associativity and its Role in Categories",
    "section": "4.2 The Category of Sets (Set Theory)",
    "text": "4.2 The Category of Sets (Set Theory)\nThis category, called Set, consists of sets and functions between them. The creation of the category Set follows a process where the internal structure of the sets and their elements is forgotten. We only care about the morphisms (functions) and their composition.\n\n4.2.1 Forgetting the Structure\nOnce you form a category, you forget about the internal structure of the objects. The objects (sets) become “atoms” with no internal properties, and you focus solely on how they are connected to other objects through morphisms (functions).\n\nIn the category Set, sets are objects, and the morphisms are functions between them.\nYou build a multiplication table (composition table) that defines how these morphisms can be composed, and this composition follows the axioms of category theory (associativity, identity).\n\n\n\n4.2.2 Composition Table\nIn the category of sets, you can think of each function between two sets as an arrow. The composition of these arrows is simply the composition of the functions. The identity function for each set ensures that the composition works according to the rules of category theory."
  },
  {
    "objectID": "category_theory.html#abstraction-and-data-hiding",
    "href": "category_theory.html#abstraction-and-data-hiding",
    "title": "2  Associativity and its Role in Categories",
    "section": "4.3 Abstraction and Data Hiding",
    "text": "4.3 Abstraction and Data Hiding\nCategory theory represents a higher level of abstraction. Once you form a category from sets, you forget about the internal elements of the sets. You are left with the interface of each object — how it connects to other objects through morphisms.\nThis abstraction represents the end of the road for data hiding: you don’t need to know what the internal structure of a set is, only how it connects with other sets. This is similar to the idea of data hiding in programming, where you only expose the relevant interface of a data structure.\n\n4.3.1 The Ultimate in Abstraction\nCategory theory provides a powerful tool for studying mathematical structures at a high level of abstraction. It allows us to work with objects and morphisms without worrying about the specifics of their internal construction. It is, in a sense, the ultimate language for abstraction."
  },
  {
    "objectID": "intro.html#example-in-mltt-proving-implication",
    "href": "intro.html#example-in-mltt-proving-implication",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "5.2 Example in MLTT (Proving Implication)",
    "text": "5.2 Example in MLTT (Proving Implication)\nLet’s prove the implication A → B, where A and B are types (propositions).\n\n5.2.1 Steps:\n\nAssume a function f: A → B exists.\nThis means that for every element of type A, the function f produces an element of type B.\nProve A → B\nTo prove the implication, we must show that for any element a of type A, we can derive an element b of type B.\nUse f to transform elements of A into elements of B.\nSince f is of type A → B, it provides us with a proof. For example, if a is an element of type A, applying f(a) gives us an element of type B.\n\n\n\n5.2.2 Example:\n\nLet A be the type of natural numbers greater than 0.\nLet B be the type of even numbers.\nWe assume f: A → B such that f(a) returns an even number for every a &gt; 0.\n\nThe function f can be a function that returns the next even number greater than a."
  },
  {
    "objectID": "intro.html#the-correspondence",
    "href": "intro.html#the-correspondence",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "6.1 The Correspondence",
    "text": "6.1 The Correspondence\n\n6.1.1 Logic ↔︎ Type Theory\n\nIn logic, a proof is a sequence of steps that proves a statement.\nIn type theory, a type represents a proposition, and a term (a function) is a proof of that type.\n\n\n6.1.1.1 Example:\n\nLogical statement: (A → B) means “if A is true, then B is true.”\nType theory: (A → B) is a type, and a function that takes an element of type A and returns an element of type B is a proof of that type.\n\n\n\n\n6.1.2 Type Theory ↔︎ Category Theory\n\nIn category theory, objects are types, and morphisms (arrows) are functions between types.\nIn type theory, a term (proof) is a morphism that transforms one object (type) into another.\n\n\n6.1.2.1 Example:\n\nIn category theory, a morphism from object A to object B represents a function from type A to type B."
  },
  {
    "objectID": "intro.html#step-by-step-example-of-the-curry-howard-lambek-isomorphism",
    "href": "intro.html#step-by-step-example-of-the-curry-howard-lambek-isomorphism",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "6.2 Step-by-Step Example of the Curry-Howard-Lambek Isomorphism",
    "text": "6.2 Step-by-Step Example of the Curry-Howard-Lambek Isomorphism\nLet’s walk through how a logical statement, a type in type theory, and a morphism in category theory are related.\n\n6.2.1 Logical Statement:\n\nConsider the logical statement (A → B), which means “if A is true, then B is true.”\n\n\n\n6.2.2 In Type Theory:\n\nThe logical statement A → B corresponds to the type A → B in type theory.\nA function of type A → B is a proof of this implication. It takes an element of type A and returns an element of type B.\n\n\n\n6.2.3 In Category Theory:\n\nIn category theory, the objects are types (A, B).\nThe morphisms (arrows) between objects represent functions. So, a morphism from object A to object B represents a function that transforms elements of type A into elements of type B.\n\nThus, the Curry-Howard-Lambek Isomorphism tells us that: - The logical statement (A → B) is represented by a type A → B. - A proof of this logical statement corresponds to a term (function) of type A → B. - In category theory, this is captured as a morphism from object A to object B.\n\n\n6.2.4 Concrete Example:\n\nLet A = {1, 2, 3, ...} and B = {2, 4, 6, 8, ...}.\nA function f: A → B that proves “if a number is natural, then it is even” could map each element a from A to the next even number b in B:\n\nf(1) = 2, f(2) = 4, f(3) = 6, ....\n\n\nIn category theory, the function f is a morphism between objects A and B. In type theory, f is a term of type A → B. In logic, f is a proof of the statement “if A, then B.”"
  },
  {
    "objectID": "intro.html#the-low-level-perspective",
    "href": "intro.html#the-low-level-perspective",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.1 The Low-Level Perspective",
    "text": "1.1 The Low-Level Perspective\nAt the lowest level of computing, everything is just bytes—binary sequences of 0s and 1s. These bytes represent data—whether numbers, text, images, or sound—everything you interact with on your computer is ultimately made up of bytes.\nFor example, consider the byte 01001000. In binary encoding, this byte represents the character 'H' in the ASCII character set. Similarly, 01100101 represents 'e', and 01101100 represents 'l'. A sequence of these bytes might represent an entire message, such as the word “Hello”.\nBytes are the raw material of computing, but they don’t mean much on their own unless we impose some structure. That’s where types come in. Type theory provides a way to give structure to these raw bytes. In a type system, we classify data into categories or types. This makes it easier to reason about and manipulate the data. For instance, we could classify 01001000 as a character or 01100101 as an integer, depending on the context."
  },
  {
    "objectID": "intro.html#type-theory-in-mathematics",
    "href": "intro.html#type-theory-in-mathematics",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.2 Type Theory in Mathematics",
    "text": "1.2 Type Theory in Mathematics\nAlthough type theory was originally developed to improve computing, its roots lie in mathematics. The history of type theory can be traced back to logical paradoxes in set theory. Let’s explore one of the most famous of these paradoxes: Russell’s Paradox.\n\n1.2.1 Russell’s Paradox: A Deeper Look\nIn 1901, Bertrand Russell discovered a paradox in set theory, which is the branch of mathematics that deals with collections of objects. The paradox arises when you try to define the set of all sets that do not contain themselves.\nLet’s break it down:\n\nConsider the set ( R ), defined as: “the set of all sets that do not contain themselves.”\n\nNow, ask yourself: Does the set ( R ) contain itself?\n\nIf ( R ) contains itself, then by its definition, it must not contain itself, because it only contains sets that do not contain themselves.\nIf ( R ) does not contain itself, then by its definition, it must contain itself because it is a set that does not contain itself.\n\nThis creates a contradiction.\nTo solve this, Russell proposed introducing a type system to prevent sets from containing themselves. In this system, we can categorize sets into levels or types, so that a set cannot be a member of itself, thus avoiding the paradox.\n\n\n\n1.2.2 The Solution via Type Theory\nRussell’s type system was the precursor to type theory as we know it today. He proposed a hierarchy of sets—called types—to organize sets and avoid paradoxes like the one above.\n\n1.2.2.1 Example: Types in Set Theory\n\nType 0: Sets that do not contain themselves.\nType 1: Sets that contain only sets from Type 0.\nType 2: Sets that contain only sets from Type 1, and so on.\n\nWith this hierarchical structure, a set of Type 0 cannot contain itself because it can only contain sets from Type 1, which are on a higher level. By categorizing sets in this way, Russell’s system ensured that paradoxes like the one mentioned above would not occur.\nThis idea of types would go on to influence the development of Martin-Löf Type Theory (MLTT), a more sophisticated type system that is widely used in both mathematics and computer science."
  },
  {
    "objectID": "intro.html#martin-löf-type-theory-mltt",
    "href": "intro.html#martin-löf-type-theory-mltt",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.3 Martin-Löf Type Theory (MLTT)",
    "text": "1.3 Martin-Löf Type Theory (MLTT)\n\n1.3.1 Key Ideas in MLTT\n\n1.3.1.1 Types as Sets\nIn MLTT, types are collections of objects, similar to sets in set theory. For example, the type Nat (natural numbers) contains objects like 0, 1, 2, etc.\n\n1.3.1.1.1 Example:\nLet’s define the type Nat: - Nat = {0, 1, 2, 3, ...}.\nThis means the elements of the type Nat are natural numbers.\n\n\n\n1.3.1.2 Types as Propositions\nIn MLTT, types can also represent logical propositions. A type A → B represents the proposition “if A is true, then B is true.”\n\n1.3.1.2.1 Example:\nLet A be the type of natural numbers greater than 0, and B be the type of even numbers: - A = {1, 2, 3, 4, ...}. - B = {2, 4, 6, 8, ...}.\nThe type A → B means “if a number is greater than 0, then it is an even number.”\n\n\n\n1.3.1.3 Proofs as Objects\nIn MLTT, a proof of a proposition is itself a term of a specific type. So, a proof of A → B is a function that takes an element of type A and returns an element of type B.\n\n1.3.1.3.1 Example:\nLet’s define a function f: A → B that proves “if a number is greater than 0, then it is even.” We could define f as follows: - f(1) = 2, f(2) = 4, f(3) = 6, etc.\nHere, f is a function that constructs even numbers, proving the implication A → B.\n\n\n\n1.3.1.4 Constructive Proofs\nMLTT insists on constructive proofs. This means if we prove the existence of an object, we must provide a concrete example.\n\n1.3.1.4.1 Example:\nTo prove “there exists an even number greater than 0,” we must construct such a number: - f: Nat where f could return 2, which is the smallest even number greater than 0.\n\n\n\n\n1.3.2 Example in MLTT (Proving Implication)\nLet’s prove the implication A → B, where A and B are types (propositions).\n\n1.3.2.1 Steps:\n\nAssume a function f: A → B exists.\nThis means that for every element of type A, the function f produces an element of type B.\nProve A → B\nTo prove the implication, we must show that for any element a of type A, we can derive an element b of type B.\nUse f to transform elements of A into elements of B.\nSince f is of type A → B, it provides us with a proof. For example, if a is an element of type A, applying f(a) gives us an element of type B.\n\n\n\n1.3.2.2 Example:\n\nLet A be the type of natural numbers greater than 0.\nLet B be the type of even numbers.\nWe assume f: A → B such that f(a) returns an even number for every a &gt; 0.\n\nThe function f can be a function that returns the next even number greater than a."
  },
  {
    "objectID": "intro.html#the-curry-howard-lambek-isomorphism",
    "href": "intro.html#the-curry-howard-lambek-isomorphism",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.4 The Curry-Howard-Lambek Isomorphism",
    "text": "1.4 The Curry-Howard-Lambek Isomorphism\n\n1.4.1 The Correspondence\n\n1.4.1.1 Logic ↔︎ Type Theory\n\nIn logic, a proof is a sequence of steps that proves a statement.\nIn type theory, a type represents a proposition, and a term (a function) is a proof of that type.\n\n\n1.4.1.1.1 Example:\n\nLogical statement: (A → B) means “if A is true, then B is true.”\nType theory: (A → B) is a type, and a function that takes an element of type A and returns an element of type B is a proof of that type.\n\n\n\n\n1.4.1.2 Type Theory ↔︎ Category Theory\n\nIn category theory, objects are types, and morphisms (arrows) are functions between types.\nIn type theory, a term (proof) is a morphism that transforms one object (type) into another.\n\n\n1.4.1.2.1 Example:\n\nIn category theory, a morphism from object A to object B represents a function from type A to type B.\n\n\n\n\n\n1.4.2 Step-by-Step Example of the Curry-Howard-Lambek Isomorphism\nLet’s walk through how a logical statement, a type in type theory, and a morphism in category theory are related.\n\n1.4.2.1 Logical Statement:\n\nConsider the logical statement (A → B), which means “if A is true, then B is true.”\n\n\n\n1.4.2.2 In Type Theory:\n\nThe logical statement A → B corresponds to the type A → B in type theory.\nA function of type A → B is a proof of this implication. It takes an element of type A and returns an element of type B.\n\n\n\n1.4.2.3 In Category Theory:\n\nIn category theory, the objects are types (A, B).\nThe morphisms (arrows) between objects represent functions. So, a morphism from object A to object B represents a function that transforms elements of type A into elements of type B.\n\nThus, the Curry-Howard-Lambek Isomorphism tells us that: - The logical statement (A → B) is represented by a type A → B. - A proof of this logical statement corresponds to a term (function) of type A → B. - In category theory, this is captured as a morphism from object A to object B.\n\n\n1.4.2.4 Concrete Example:\n\nLet A = {1, 2, 3, ...} and B = {2, 4, 6, 8, ...}.\nA function f: A → B that proves “if a number is natural, then it is even” could map each element a from A to the next even number b in B:\n\nf(1) = 2, f(2) = 4, f(3) = 6, ....\n\n\nIn category theory, the function f is a morphism between objects A and B. In type theory, f is a term of type A → B. In logic, f is a proof of the statement “if A, then B.”"
  },
  {
    "objectID": "intro.html#the-nature-of-mathematics-discovery-or-invention",
    "href": "intro.html#the-nature-of-mathematics-discovery-or-invention",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.5 The Nature of Mathematics: Discovery or Invention?",
    "text": "1.5 The Nature of Mathematics: Discovery or Invention?\nMathematicians often debate whether mathematics is an invention of the human mind or a discovery of universal truths. Unlike physicists, who conduct experiments to uncover the natural laws of the universe, mathematicians engage in abstract reasoning and logical deduction. Despite this, different branches of mathematics often uncover equivalent structures, suggesting that there may be some underlying objective reality to these concepts."
  },
  {
    "objectID": "intro.html#the-limits-of-human-cognition",
    "href": "intro.html#the-limits-of-human-cognition",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.6 The Limits of Human Cognition",
    "text": "1.6 The Limits of Human Cognition\nHumans evolved primarily for survival—identifying threats, securing food, and navigating social relationships. Our brains are excellent at dealing with concrete, immediate problems, but abstract reasoning is a more recent development. To handle complexity, we often use decomposition—breaking complex problems into simpler, manageable parts.\nThis principle, found in everything from science to programming, is central to how we understand and solve problems."
  },
  {
    "objectID": "intro.html#is-the-universe-fundamentally-composable",
    "href": "intro.html#is-the-universe-fundamentally-composable",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.7 Is the Universe Fundamentally Composable?",
    "text": "1.7 Is the Universe Fundamentally Composable?\nIn physics, scientists have long adhered to a reductionist approach—breaking matter down into smaller and smaller components. For instance, atoms are composed of protons, neutrons, and electrons, which are themselves composed of quarks. However, recent developments in physics challenge this reductionist view:\n\nQuantum mechanics shows that particles don’t behave like simple building blocks.\nString theory suggests that the fundamental particles are not points, but tiny vibrating strings.\n\nThese discoveries raise a profound question: is the universe inherently composable, or is this just a human cognitive strategy?"
  },
  {
    "objectID": "intro.html#category-theory-as-a-study-of-human-thought",
    "href": "intro.html#category-theory-as-a-study-of-human-thought",
    "title": "1  Understanding Category Theory, Type Theory, and Logic",
    "section": "1.8 Category Theory as a Study of Human Thought",
    "text": "1.8 Category Theory as a Study of Human Thought\nCategory theory, often seen as a highly abstract branch of mathematics, may not be as concerned with the intrinsic nature of the universe as we might think. Instead, it provides a framework for understanding how humans reason about complexity. It describes patterns and structures that our minds impose on the problems we encounter.\nIn this sense, category theory might be more about epistemology—how we understand the world—than ontology—what the world actually is."
  }
]